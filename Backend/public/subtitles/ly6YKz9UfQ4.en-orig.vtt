WEBVTT
Kind: captions
Language: en

00:00:00.240 --> 00:00:02.310 align:start position:0%
 
Last<00:00:00.560><c> week,</c><00:00:00.800><c> Mark</c><00:00:01.120><c> Zuckerberg</c><00:00:01.760><c> put</c><00:00:01.920><c> a</c><00:00:02.080><c> freeze</c>

00:00:02.310 --> 00:00:02.320 align:start position:0%
Last week, Mark Zuckerberg put a freeze
 

00:00:02.320 --> 00:00:04.710 align:start position:0%
Last week, Mark Zuckerberg put a freeze
on<00:00:02.480><c> all</c><00:00:02.720><c> AI</c><00:00:03.120><c> hiring</c><00:00:03.520><c> at</c><00:00:03.679><c> Meta,</c><00:00:04.240><c> just</c><00:00:04.480><c> weeks</c>

00:00:04.710 --> 00:00:04.720 align:start position:0%
on all AI hiring at Meta, just weeks
 

00:00:04.720 --> 00:00:06.230 align:start position:0%
on all AI hiring at Meta, just weeks
after<00:00:05.040><c> spending</c><00:00:05.440><c> billions</c><00:00:05.759><c> of</c><00:00:05.920><c> dollars</c>

00:00:06.230 --> 00:00:06.240 align:start position:0%
after spending billions of dollars
 

00:00:06.240 --> 00:00:07.990 align:start position:0%
after spending billions of dollars
poaching<00:00:06.720><c> top</c><00:00:06.960><c> talent</c><00:00:07.279><c> from</c><00:00:07.520><c> competitors</c>

00:00:07.990 --> 00:00:08.000 align:start position:0%
poaching top talent from competitors
 

00:00:08.000 --> 00:00:10.390 align:start position:0%
poaching top talent from competitors
like<00:00:08.240><c> Open</c><00:00:08.559><c> AI.</c><00:00:09.040><c> Meanwhile,</c><00:00:09.519><c> in</c><00:00:09.679><c> a</c><00:00:09.840><c> story</c><00:00:10.080><c> few</c>

00:00:10.390 --> 00:00:10.400 align:start position:0%
like Open AI. Meanwhile, in a story few
 

00:00:10.400 --> 00:00:11.910 align:start position:0%
like Open AI. Meanwhile, in a story few
could<00:00:10.480><c> have</c><00:00:10.639><c> foreseen,</c><00:00:11.360><c> everybody</c><00:00:11.679><c> in</c>

00:00:11.910 --> 00:00:11.920 align:start position:0%
could have foreseen, everybody in
 

00:00:11.920 --> 00:00:13.669 align:start position:0%
could have foreseen, everybody in
Silicon<00:00:12.400><c> Valley</c><00:00:12.719><c> seems</c><00:00:13.040><c> to</c><00:00:13.120><c> be</c><00:00:13.280><c> talking</c><00:00:13.519><c> about</c>

00:00:13.669 --> 00:00:13.679 align:start position:0%
Silicon Valley seems to be talking about
 

00:00:13.679 --> 00:00:15.990 align:start position:0%
Silicon Valley seems to be talking about
an<00:00:13.920><c> AI</c><00:00:14.240><c> bubble.</c><00:00:14.880><c> In</c><00:00:15.120><c> part,</c><00:00:15.440><c> because</c><00:00:15.599><c> it</c><00:00:15.839><c> was</c>

00:00:15.990 --> 00:00:16.000 align:start position:0%
an AI bubble. In part, because it was
 

00:00:16.000 --> 00:00:19.109 align:start position:0%
an AI bubble. In part, because it was
recently<00:00:16.400><c> revealed</c><00:00:16.880><c> that</c><00:00:17.199><c> 95%</c><00:00:18.080><c> of</c><00:00:18.320><c> AIdriven</c>

00:00:19.109 --> 00:00:19.119 align:start position:0%
recently revealed that 95% of AIdriven
 

00:00:19.119 --> 00:00:20.870 align:start position:0%
recently revealed that 95% of AIdriven
projects<00:00:19.600><c> fail.</c><00:00:20.080><c> And</c><00:00:20.240><c> that's</c><00:00:20.400><c> not</c><00:00:20.560><c> just</c><00:00:20.720><c> some</c>

00:00:20.870 --> 00:00:20.880 align:start position:0%
projects fail. And that's not just some
 

00:00:20.880 --> 00:00:22.630 align:start position:0%
projects fail. And that's not just some
random<00:00:21.199><c> number</c><00:00:21.439><c> I</c><00:00:21.600><c> pulled</c><00:00:21.840><c> out</c><00:00:21.920><c> of</c><00:00:22.080><c> nowhere.</c>

00:00:22.630 --> 00:00:22.640 align:start position:0%
random number I pulled out of nowhere.
 

00:00:22.640 --> 00:00:24.950 align:start position:0%
random number I pulled out of nowhere.
It's<00:00:22.800><c> based</c><00:00:23.039><c> on</c><00:00:23.119><c> an</c><00:00:23.359><c> MIT</c><00:00:23.920><c> study</c><00:00:24.240><c> that</c><00:00:24.480><c> analyzed</c>

00:00:24.950 --> 00:00:24.960 align:start position:0%
It's based on an MIT study that analyzed
 

00:00:24.960 --> 00:00:27.109 align:start position:0%
It's based on an MIT study that analyzed
the<00:00:25.199><c> results</c><00:00:25.439><c> of</c><00:00:25.680><c> companies</c><00:00:26.080><c> using</c><00:00:26.400><c> AI.</c><00:00:26.880><c> It</c>

00:00:27.109 --> 00:00:27.119 align:start position:0%
the results of companies using AI. It
 

00:00:27.119 --> 00:00:29.109 align:start position:0%
the results of companies using AI. It
spooked<00:00:27.439><c> investors</c><00:00:27.920><c> who</c><00:00:28.160><c> are</c><00:00:28.320><c> relying</c><00:00:28.560><c> on</c><00:00:28.800><c> AI</c>

00:00:29.109 --> 00:00:29.119 align:start position:0%
spooked investors who are relying on AI
 

00:00:29.119 --> 00:00:31.109 align:start position:0%
spooked investors who are relying on AI
to<00:00:29.359><c> maintain</c><00:00:29.679><c> irrational</c><00:00:30.240><c> exuberance</c><00:00:30.800><c> in</c><00:00:30.960><c> the</c>

00:00:31.109 --> 00:00:31.119 align:start position:0%
to maintain irrational exuberance in the
 

00:00:31.119 --> 00:00:33.030 align:start position:0%
to maintain irrational exuberance in the
markets.<00:00:31.599><c> And</c><00:00:31.760><c> Sam</c><00:00:32.079><c> Alman</c><00:00:32.480><c> himself</c><00:00:32.800><c> said</c>

00:00:33.030 --> 00:00:33.040 align:start position:0%
markets. And Sam Alman himself said
 

00:00:33.040 --> 00:00:34.950 align:start position:0%
markets. And Sam Alman himself said
this.<00:00:33.440><c> Are</c><00:00:33.600><c> we</c><00:00:33.680><c> in</c><00:00:33.840><c> a</c><00:00:34.000><c> phase</c><00:00:34.239><c> where</c><00:00:34.399><c> investors</c>

00:00:34.950 --> 00:00:34.960 align:start position:0%
this. Are we in a phase where investors
 

00:00:34.960 --> 00:00:37.430 align:start position:0%
this. Are we in a phase where investors
as<00:00:35.120><c> a</c><00:00:35.280><c> whole</c><00:00:35.440><c> are</c><00:00:35.600><c> over</c><00:00:35.920><c> excited</c><00:00:36.239><c> about</c><00:00:36.480><c> AI?</c><00:00:37.200><c> In</c>

00:00:37.430 --> 00:00:37.440 align:start position:0%
as a whole are over excited about AI? In
 

00:00:37.440 --> 00:00:39.510 align:start position:0%
as a whole are over excited about AI? In
my<00:00:37.600><c> opinion,</c><00:00:38.079><c> yes.</c><00:00:38.559><c> So,</c><00:00:38.800><c> in</c><00:00:38.960><c> today's</c><00:00:39.200><c> video,</c>

00:00:39.510 --> 00:00:39.520 align:start position:0%
my opinion, yes. So, in today's video,
 

00:00:39.520 --> 00:00:41.270 align:start position:0%
my opinion, yes. So, in today's video,
we'll<00:00:39.760><c> find</c><00:00:39.840><c> out</c><00:00:40.000><c> if</c><00:00:40.160><c> the</c><00:00:40.320><c> AI</c><00:00:40.559><c> hype</c><00:00:40.879><c> train</c><00:00:41.120><c> is</c>

00:00:41.270 --> 00:00:41.280 align:start position:0%
we'll find out if the AI hype train is
 

00:00:41.280 --> 00:00:42.869 align:start position:0%
we'll find out if the AI hype train is
about<00:00:41.360><c> to</c><00:00:41.520><c> reach</c><00:00:41.680><c> its</c><00:00:41.920><c> terminus.</c><00:00:42.480><c> It</c><00:00:42.719><c> is</c>

00:00:42.869 --> 00:00:42.879 align:start position:0%
about to reach its terminus. It is
 

00:00:42.879 --> 00:00:45.350 align:start position:0%
about to reach its terminus. It is
August<00:00:43.200><c> 25th,</c><00:00:43.760><c> 2025,</c><00:00:44.559><c> and</c><00:00:44.879><c> you're</c><00:00:45.120><c> watching</c>

00:00:45.350 --> 00:00:45.360 align:start position:0%
August 25th, 2025, and you're watching
 

00:00:45.360 --> 00:00:47.110 align:start position:0%
August 25th, 2025, and you're watching
the<00:00:45.520><c> code</c><00:00:45.840><c> report.</c><00:00:46.239><c> I've</c><00:00:46.399><c> been</c><00:00:46.559><c> using</c><00:00:46.719><c> AI</c>

00:00:47.110 --> 00:00:47.120 align:start position:0%
the code report. I've been using AI
 

00:00:47.120 --> 00:00:48.709 align:start position:0%
the code report. I've been using AI
coding<00:00:47.360><c> tools</c><00:00:47.680><c> from</c><00:00:47.920><c> the</c><00:00:48.079><c> very</c><00:00:48.239><c> beginning</c>

00:00:48.709 --> 00:00:48.719 align:start position:0%
coding tools from the very beginning
 

00:00:48.719 --> 00:00:50.310 align:start position:0%
coding tools from the very beginning
because,<00:00:49.039><c> believe</c><00:00:49.280><c> it</c><00:00:49.360><c> or</c><00:00:49.520><c> not,</c><00:00:49.840><c> I</c><00:00:50.079><c> actually</c>

00:00:50.310 --> 00:00:50.320 align:start position:0%
because, believe it or not, I actually
 

00:00:50.320 --> 00:00:52.389 align:start position:0%
because, believe it or not, I actually
hate<00:00:50.640><c> writing</c><00:00:50.960><c> code.</c><00:00:51.360><c> I</c><00:00:51.520><c> do</c><00:00:51.680><c> like</c><00:00:51.840><c> developing</c>

00:00:52.389 --> 00:00:52.399 align:start position:0%
hate writing code. I do like developing
 

00:00:52.399 --> 00:00:54.069 align:start position:0%
hate writing code. I do like developing
software,<00:00:52.879><c> and</c><00:00:53.039><c> the</c><00:00:53.280><c> code</c><00:00:53.440><c> is</c><00:00:53.600><c> just</c><00:00:53.760><c> a</c><00:00:53.920><c> means</c>

00:00:54.069 --> 00:00:54.079 align:start position:0%
software, and the code is just a means
 

00:00:54.079 --> 00:00:55.830 align:start position:0%
software, and the code is just a means
to<00:00:54.239><c> an</c><00:00:54.399><c> end.</c><00:00:54.640><c> After</c><00:00:54.960><c> multiple</c><00:00:55.280><c> years</c><00:00:55.440><c> of</c><00:00:55.600><c> using</c>

00:00:55.830 --> 00:00:55.840 align:start position:0%
to an end. After multiple years of using
 

00:00:55.840 --> 00:00:57.510 align:start position:0%
to an end. After multiple years of using
AI<00:00:56.160><c> to</c><00:00:56.320><c> write</c><00:00:56.480><c> code,</c><00:00:56.879><c> I</c><00:00:57.039><c> still</c><00:00:57.199><c> don't</c><00:00:57.360><c> feel</c>

00:00:57.510 --> 00:00:57.520 align:start position:0%
AI to write code, I still don't feel
 

00:00:57.520 --> 00:00:59.590 align:start position:0%
AI to write code, I still don't feel
like<00:00:57.680><c> a</c><00:00:57.840><c> 10x</c><00:00:58.239><c> developer.</c><00:00:58.960><c> Sometimes</c><00:00:59.280><c> I</c><00:00:59.440><c> feel</c>

00:00:59.590 --> 00:00:59.600 align:start position:0%
like a 10x developer. Sometimes I feel
 

00:00:59.600 --> 00:01:01.830 align:start position:0%
like a 10x developer. Sometimes I feel
like<00:00:59.680><c> a</c><00:00:59.840><c> 2x</c><00:01:00.239><c> developer,</c><00:01:00.879><c> while</c><00:01:01.199><c> other</c><00:01:01.440><c> times</c><00:01:01.600><c> I</c>

00:01:01.830 --> 00:01:01.840 align:start position:0%
like a 2x developer, while other times I
 

00:01:01.840 --> 00:01:04.310 align:start position:0%
like a 2x developer, while other times I
feel<00:01:02.000><c> more</c><00:01:02.239><c> like</c><00:01:02.320><c> a</c><00:01:02.559><c> 0.5x</c><00:01:03.520><c> developer.</c><00:01:04.080><c> And</c>

00:01:04.310 --> 00:01:04.320 align:start position:0%
feel more like a 0.5x developer. And
 

00:01:04.320 --> 00:01:06.149 align:start position:0%
feel more like a 0.5x developer. And
apparently,<00:01:04.720><c> I'm</c><00:01:04.960><c> not</c><00:01:05.119><c> the</c><00:01:05.280><c> only</c><00:01:05.439><c> one.</c><00:01:05.920><c> This</c>

00:01:06.149 --> 00:01:06.159 align:start position:0%
apparently, I'm not the only one. This
 

00:01:06.159 --> 00:01:08.710 align:start position:0%
apparently, I'm not the only one. This
recent<00:01:06.479><c> study</c><00:01:06.720><c> from</c><00:01:06.960><c> MIT</c><00:01:07.680><c> analyzed</c><00:01:08.320><c> 300</c>

00:01:08.710 --> 00:01:08.720 align:start position:0%
recent study from MIT analyzed 300
 

00:01:08.720 --> 00:01:10.870 align:start position:0%
recent study from MIT analyzed 300
public<00:01:09.040><c> deployments,</c><00:01:09.760><c> interviewed</c><00:01:10.560><c> 150</c>

00:01:10.870 --> 00:01:10.880 align:start position:0%
public deployments, interviewed 150
 

00:01:10.880 --> 00:01:13.590 align:start position:0%
public deployments, interviewed 150
leaders,<00:01:11.439><c> and</c><00:01:11.680><c> surveyed</c><00:01:12.240><c> 350</c><00:01:12.960><c> employees</c>

00:01:13.590 --> 00:01:13.600 align:start position:0%
leaders, and surveyed 350 employees
 

00:01:13.600 --> 00:01:15.990 align:start position:0%
leaders, and surveyed 350 employees
connected<00:01:14.000><c> to</c><00:01:14.240><c> recent</c><00:01:14.560><c> AI</c><00:01:15.040><c> integrations.</c>

00:01:15.990 --> 00:01:16.000 align:start position:0%
connected to recent AI integrations.
 

00:01:16.000 --> 00:01:18.070 align:start position:0%
connected to recent AI integrations.
We're<00:01:16.240><c> talking</c><00:01:16.479><c> about</c><00:01:16.720><c> 30</c><00:01:16.960><c> to</c><00:01:17.280><c> 40</c><00:01:17.439><c> billion</c><00:01:17.840><c> in</c>

00:01:18.070 --> 00:01:18.080 align:start position:0%
We're talking about 30 to 40 billion in
 

00:01:18.080 --> 00:01:19.749 align:start position:0%
We're talking about 30 to 40 billion in
enterprise<00:01:18.560><c> investment</c><00:01:18.960><c> into</c><00:01:19.280><c> generative</c>

00:01:19.749 --> 00:01:19.759 align:start position:0%
enterprise investment into generative
 

00:01:19.759 --> 00:01:22.230 align:start position:0%
enterprise investment into generative
AI.<00:01:20.320><c> And</c><00:01:20.479><c> yet</c><00:01:20.640><c> it</c><00:01:20.880><c> was</c><00:01:20.960><c> found</c><00:01:21.119><c> that</c><00:01:21.360><c> 95%</c><00:01:22.080><c> of</c>

00:01:22.230 --> 00:01:22.240 align:start position:0%
AI. And yet it was found that 95% of
 

00:01:22.240 --> 00:01:24.390 align:start position:0%
AI. And yet it was found that 95% of
them<00:01:22.400><c> failed</c><00:01:22.720><c> to</c><00:01:22.960><c> achieve</c><00:01:23.200><c> the</c><00:01:23.439><c> goal</c><00:01:23.680><c> of</c><00:01:24.000><c> rapid</c>

00:01:24.390 --> 00:01:24.400 align:start position:0%
them failed to achieve the goal of rapid
 

00:01:24.400 --> 00:01:26.630 align:start position:0%
them failed to achieve the goal of rapid
revenue<00:01:24.880><c> acceleration.</c><00:01:25.840><c> In</c><00:01:26.080><c> fact,</c><00:01:26.320><c> almost</c>

00:01:26.630 --> 00:01:26.640 align:start position:0%
revenue acceleration. In fact, almost
 

00:01:26.640 --> 00:01:28.630 align:start position:0%
revenue acceleration. In fact, almost
all<00:01:26.880><c> of</c><00:01:26.960><c> them</c><00:01:27.280><c> experienced</c><00:01:28.000><c> little</c><00:01:28.240><c> to</c><00:01:28.479><c> no</c>

00:01:28.630 --> 00:01:28.640 align:start position:0%
all of them experienced little to no
 

00:01:28.640 --> 00:01:30.870 align:start position:0%
all of them experienced little to no
measurable<00:01:29.200><c> impact</c><00:01:29.520><c> on</c><00:01:29.759><c> the</c><00:01:29.920><c> bottom</c><00:01:30.240><c> line.</c><00:01:30.720><c> In</c>

00:01:30.870 --> 00:01:30.880 align:start position:0%
measurable impact on the bottom line. In
 

00:01:30.880 --> 00:01:32.469 align:start position:0%
measurable impact on the bottom line. In
addition,<00:01:31.360><c> the</c><00:01:31.520><c> study</c><00:01:31.840><c> found</c><00:01:32.000><c> that</c><00:01:32.159><c> companies</c>

00:01:32.469 --> 00:01:32.479 align:start position:0%
addition, the study found that companies
 

00:01:32.479 --> 00:01:34.069 align:start position:0%
addition, the study found that companies
that<00:01:32.720><c> tried</c><00:01:32.880><c> to</c><00:01:32.960><c> roll</c><00:01:33.200><c> out</c><00:01:33.360><c> their</c><00:01:33.520><c> own</c><00:01:33.680><c> AI</c>

00:01:34.069 --> 00:01:34.079 align:start position:0%
that tried to roll out their own AI
 

00:01:34.079 --> 00:01:36.069 align:start position:0%
that tried to roll out their own AI
tooling<00:01:34.479><c> had</c><00:01:34.720><c> a</c><00:01:34.880><c> much</c><00:01:35.040><c> higher</c><00:01:35.360><c> failure</c><00:01:35.680><c> rate</c>

00:01:36.069 --> 00:01:36.079 align:start position:0%
tooling had a much higher failure rate
 

00:01:36.079 --> 00:01:37.990 align:start position:0%
tooling had a much higher failure rate
because<00:01:36.320><c> why</c><00:01:36.560><c> pay</c><00:01:36.720><c> for</c><00:01:36.880><c> an</c><00:01:37.040><c> AI</c><00:01:37.360><c> tool</c><00:01:37.600><c> when</c><00:01:37.840><c> you</c>

00:01:37.990 --> 00:01:38.000 align:start position:0%
because why pay for an AI tool when you
 

00:01:38.000 --> 00:01:39.590 align:start position:0%
because why pay for an AI tool when you
can<00:01:38.079><c> build</c><00:01:38.240><c> a</c><00:01:38.400><c> worse</c><00:01:38.720><c> version</c><00:01:38.960><c> yourself.</c>

00:01:39.590 --> 00:01:39.600 align:start position:0%
can build a worse version yourself.
 

00:01:39.600 --> 00:01:41.109 align:start position:0%
can build a worse version yourself.
Companies<00:01:39.920><c> that</c><00:01:40.079><c> paid</c><00:01:40.320><c> a</c><00:01:40.479><c> third</c><00:01:40.640><c> party</c><00:01:40.880><c> were</c>

00:01:41.109 --> 00:01:41.119 align:start position:0%
Companies that paid a third party were
 

00:01:41.119 --> 00:01:42.710 align:start position:0%
Companies that paid a third party were
better<00:01:41.280><c> off.</c><00:01:41.680><c> And</c><00:01:41.759><c> I</c><00:01:41.920><c> think</c><00:01:42.000><c> the</c><00:01:42.159><c> moral</c><00:01:42.400><c> of</c><00:01:42.479><c> the</c>

00:01:42.710 --> 00:01:42.720 align:start position:0%
better off. And I think the moral of the
 

00:01:42.720 --> 00:01:44.230 align:start position:0%
better off. And I think the moral of the
story<00:01:42.880><c> here</c><00:01:43.119><c> is</c><00:01:43.280><c> that</c><00:01:43.520><c> it's</c><00:01:43.680><c> a</c><00:01:43.759><c> great</c><00:01:43.920><c> time</c><00:01:44.079><c> to</c>

00:01:44.230 --> 00:01:44.240 align:start position:0%
story here is that it's a great time to
 

00:01:44.240 --> 00:01:46.550 align:start position:0%
story here is that it's a great time to
be<00:01:44.400><c> an</c><00:01:44.560><c> enterprise</c><00:01:45.040><c> AI</c><00:01:45.360><c> shovel</c><00:01:45.759><c> salesman.</c><00:01:46.399><c> But</c>

00:01:46.550 --> 00:01:46.560 align:start position:0%
be an enterprise AI shovel salesman. But
 

00:01:46.560 --> 00:01:48.069 align:start position:0%
be an enterprise AI shovel salesman. But
despite<00:01:46.880><c> the</c><00:01:47.040><c> high</c><00:01:47.200><c> failure</c><00:01:47.520><c> rate</c><00:01:47.759><c> in</c><00:01:47.920><c> the</c>

00:01:48.069 --> 00:01:48.079 align:start position:0%
despite the high failure rate in the
 

00:01:48.079 --> 00:01:49.670 align:start position:0%
despite the high failure rate in the
study,<00:01:48.560><c> there</c><00:01:48.720><c> are</c><00:01:48.880><c> some</c><00:01:49.119><c> great</c><00:01:49.360><c> success</c>

00:01:49.670 --> 00:01:49.680 align:start position:0%
study, there are some great success
 

00:01:49.680 --> 00:01:52.069 align:start position:0%
study, there are some great success
stories<00:01:50.079><c> out</c><00:01:50.240><c> there.</c><00:01:50.640><c> Like</c><00:01:50.880><c> back</c><00:01:51.040><c> in</c><00:01:51.280><c> 2023,</c>

00:01:52.069 --> 00:01:52.079 align:start position:0%
stories out there. Like back in 2023,
 

00:01:52.079 --> 00:01:54.550 align:start position:0%
stories out there. Like back in 2023,
enterprise<00:01:52.560><c> software</c><00:01:53.040><c> company</c><00:01:53.360><c> Ignite</c><00:01:54.079><c> CEO</c>

00:01:54.550 --> 00:01:54.560 align:start position:0%
enterprise software company Ignite CEO
 

00:01:54.560 --> 00:01:57.429 align:start position:0%
enterprise software company Ignite CEO
Eric<00:01:54.880><c> Vaughn</c><00:01:55.680><c> fired</c><00:01:56.000><c> 80%</c><00:01:56.479><c> of</c><00:01:56.640><c> his</c><00:01:56.880><c> developers</c>

00:01:57.429 --> 00:01:57.439 align:start position:0%
Eric Vaughn fired 80% of his developers
 

00:01:57.439 --> 00:01:59.590 align:start position:0%
Eric Vaughn fired 80% of his developers
and<00:01:57.759><c> replaced</c><00:01:58.079><c> them</c><00:01:58.240><c> with</c><00:01:58.399><c> AI.</c><00:01:58.960><c> It's</c><00:01:59.200><c> now</c><00:01:59.439><c> 2</c>

00:01:59.590 --> 00:01:59.600 align:start position:0%
and replaced them with AI. It's now 2
 

00:01:59.600 --> 00:02:01.670 align:start position:0%
and replaced them with AI. It's now 2
years<00:01:59.759><c> later</c><00:02:00.240><c> and</c><00:02:00.399><c> he</c><00:02:00.560><c> has</c><00:02:00.719><c> no</c><00:02:00.960><c> regrets</c><00:02:01.439><c> and</c>

00:02:01.670 --> 00:02:01.680 align:start position:0%
years later and he has no regrets and
 

00:02:01.680 --> 00:02:04.389 align:start position:0%
years later and he has no regrets and
says<00:02:01.920><c> the</c><00:02:02.159><c> decision</c><00:02:02.479><c> is</c><00:02:02.719><c> now</c><00:02:02.960><c> delivering</c><00:02:03.520><c> 75%</c>

00:02:04.389 --> 00:02:04.399 align:start position:0%
says the decision is now delivering 75%
 

00:02:04.399 --> 00:02:06.469 align:start position:0%
says the decision is now delivering 75%
profit<00:02:04.799><c> margins.</c><00:02:05.520><c> And</c><00:02:05.759><c> ultimately,</c><00:02:06.240><c> the</c>

00:02:06.469 --> 00:02:06.479 align:start position:0%
profit margins. And ultimately, the
 

00:02:06.479 --> 00:02:08.550 align:start position:0%
profit margins. And ultimately, the
interpretation<00:02:06.960><c> of</c><00:02:07.119><c> the</c><00:02:07.280><c> MIT</c><00:02:07.840><c> study</c><00:02:08.239><c> was</c><00:02:08.399><c> that</c>

00:02:08.550 --> 00:02:08.560 align:start position:0%
interpretation of the MIT study was that
 

00:02:08.560 --> 00:02:10.309 align:start position:0%
interpretation of the MIT study was that
it's<00:02:08.800><c> not</c><00:02:08.879><c> the</c><00:02:09.119><c> fault</c><00:02:09.280><c> of</c><00:02:09.360><c> the</c><00:02:09.520><c> AI</c><00:02:09.920><c> models</c><00:02:10.160><c> that</c>

00:02:10.309 --> 00:02:10.319 align:start position:0%
it's not the fault of the AI models that
 

00:02:10.319 --> 00:02:12.309 align:start position:0%
it's not the fault of the AI models that
the<00:02:10.479><c> AI</c><00:02:10.800><c> sucks</c><00:02:11.039><c> at</c><00:02:11.280><c> making</c><00:02:11.520><c> money.</c><00:02:11.840><c> The</c><00:02:12.080><c> models</c>

00:02:12.309 --> 00:02:12.319 align:start position:0%
the AI sucks at making money. The models
 

00:02:12.319 --> 00:02:13.990 align:start position:0%
the AI sucks at making money. The models
are<00:02:12.560><c> definitely</c><00:02:12.959><c> smart</c><00:02:13.200><c> enough.</c><00:02:13.680><c> It's</c><00:02:13.840><c> just</c>

00:02:13.990 --> 00:02:14.000 align:start position:0%
are definitely smart enough. It's just
 

00:02:14.000 --> 00:02:15.830 align:start position:0%
are definitely smart enough. It's just
the<00:02:14.160><c> humans</c><00:02:14.480><c> suck</c><00:02:14.720><c> at</c><00:02:14.959><c> using</c><00:02:15.200><c> them.</c><00:02:15.599><c> It's</c>

00:02:15.830 --> 00:02:15.840 align:start position:0%
the humans suck at using them. It's
 

00:02:15.840 --> 00:02:17.589 align:start position:0%
the humans suck at using them. It's
nothing<00:02:16.080><c> but</c><00:02:16.319><c> a</c><00:02:16.480><c> skill</c><00:02:16.720><c> issue.</c><00:02:17.120><c> The</c><00:02:17.280><c> AI</c>

00:02:17.589 --> 00:02:17.599 align:start position:0%
nothing but a skill issue. The AI
 

00:02:17.599 --> 00:02:19.430 align:start position:0%
nothing but a skill issue. The AI
integrations<00:02:18.239><c> failed</c><00:02:18.560><c> due</c><00:02:18.800><c> to</c><00:02:19.040><c> brittle</c>

00:02:19.430 --> 00:02:19.440 align:start position:0%
integrations failed due to brittle
 

00:02:19.440 --> 00:02:21.430 align:start position:0%
integrations failed due to brittle
workflows,<00:02:20.160><c> lack</c><00:02:20.400><c> of</c><00:02:20.640><c> context,</c><00:02:21.200><c> and</c>

00:02:21.430 --> 00:02:21.440 align:start position:0%
workflows, lack of context, and
 

00:02:21.440 --> 00:02:23.750 align:start position:0%
workflows, lack of context, and
misalignment<00:02:22.080><c> with</c><00:02:22.239><c> day-to-day</c><00:02:22.800><c> operations.</c>

00:02:23.750 --> 00:02:23.760 align:start position:0%
misalignment with day-to-day operations.
 

00:02:23.760 --> 00:02:25.910 align:start position:0%
misalignment with day-to-day operations.
Many<00:02:24.000><c> have</c><00:02:24.160><c> failed</c><00:02:24.400><c> to</c><00:02:24.560><c> realize</c><00:02:24.959><c> that</c><00:02:25.200><c> AI</c><00:02:25.599><c> vibe</c>

00:02:25.910 --> 00:02:25.920 align:start position:0%
Many have failed to realize that AI vibe
 

00:02:25.920 --> 00:02:28.309 align:start position:0%
Many have failed to realize that AI vibe
coding<00:02:26.239><c> is</c><00:02:26.480><c> almost</c><00:02:26.959><c> identical</c><00:02:27.280><c> to</c><00:02:27.440><c> crack.</c>

00:02:28.309 --> 00:02:28.319 align:start position:0%
coding is almost identical to crack.
 

00:02:28.319 --> 00:02:29.589 align:start position:0%
coding is almost identical to crack.
After<00:02:28.560><c> the</c><00:02:28.800><c> first</c><00:02:28.959><c> hit,</c><00:02:29.280><c> you</c><00:02:29.440><c> feel</c>

00:02:29.589 --> 00:02:29.599 align:start position:0%
After the first hit, you feel
 

00:02:29.599 --> 00:02:31.110 align:start position:0%
After the first hit, you feel
invincible,<00:02:30.319><c> like</c><00:02:30.560><c> you</c><00:02:30.720><c> could</c><00:02:30.800><c> write</c><00:02:30.959><c> a</c>

00:02:31.110 --> 00:02:31.120 align:start position:0%
invincible, like you could write a
 

00:02:31.120 --> 00:02:32.630 align:start position:0%
invincible, like you could write a
billion<00:02:31.440><c> dollar</c><00:02:31.680><c> piece</c><00:02:31.840><c> of</c><00:02:32.000><c> software</c><00:02:32.319><c> in</c>

00:02:32.630 --> 00:02:32.640 align:start position:0%
billion dollar piece of software in
 

00:02:32.640 --> 00:02:34.869 align:start position:0%
billion dollar piece of software in
hours.<00:02:33.280><c> But</c><00:02:33.360><c> then</c><00:02:33.680><c> 200</c><00:02:34.000><c> hits</c><00:02:34.319><c> later,</c><00:02:34.720><c> you've</c>

00:02:34.869 --> 00:02:34.879 align:start position:0%
hours. But then 200 hits later, you've
 

00:02:34.879 --> 00:02:37.430 align:start position:0%
hours. But then 200 hits later, you've
got<00:02:35.040><c> nothing</c><00:02:35.280><c> but</c><00:02:35.599><c> errors</c><00:02:35.840><c> in</c><00:02:36.160><c> $100,000</c><00:02:36.879><c> cla</c>

00:02:37.430 --> 00:02:37.440 align:start position:0%
got nothing but errors in $100,000 cla
 

00:02:37.440 --> 00:02:38.790 align:start position:0%
got nothing but errors in $100,000 cla
bill,<00:02:37.680><c> and</c><00:02:37.920><c> you're</c><00:02:38.080><c> still</c><00:02:38.239><c> convinced</c><00:02:38.560><c> that</c>

00:02:38.790 --> 00:02:38.800 align:start position:0%
bill, and you're still convinced that
 

00:02:38.800 --> 00:02:40.150 align:start position:0%
bill, and you're still convinced that
the<00:02:38.959><c> next</c><00:02:39.120><c> prompt</c><00:02:39.440><c> is</c><00:02:39.680><c> going</c><00:02:39.760><c> to</c><00:02:39.840><c> be</c><00:02:39.920><c> the</c><00:02:40.080><c> one</c>

00:02:40.150 --> 00:02:40.160 align:start position:0%
the next prompt is going to be the one
 

00:02:40.160 --> 00:02:41.830 align:start position:0%
the next prompt is going to be the one
that<00:02:40.319><c> fixes</c><00:02:40.640><c> it</c><00:02:40.800><c> all.</c><00:02:41.040><c> With</c><00:02:41.200><c> all</c><00:02:41.360><c> the</c><00:02:41.440><c> slop</c>

00:02:41.830 --> 00:02:41.840 align:start position:0%
that fixes it all. With all the slop
 

00:02:41.840 --> 00:02:43.589 align:start position:0%
that fixes it all. With all the slop
intensifying,<00:02:42.560><c> it</c><00:02:42.720><c> looks</c><00:02:42.879><c> like</c><00:02:43.120><c> programmers</c>

00:02:43.589 --> 00:02:43.599 align:start position:0%
intensifying, it looks like programmers
 

00:02:43.599 --> 00:02:45.190 align:start position:0%
intensifying, it looks like programmers
should<00:02:43.760><c> still</c><00:02:43.920><c> have</c><00:02:44.080><c> a</c><00:02:44.239><c> job</c><00:02:44.480><c> writing</c><00:02:44.800><c> code</c><00:02:44.959><c> for</c>

00:02:45.190 --> 00:02:45.200 align:start position:0%
should still have a job writing code for
 

00:02:45.200 --> 00:02:47.110 align:start position:0%
should still have a job writing code for
the<00:02:45.360><c> foreseeable</c><00:02:45.920><c> future,</c><00:02:46.560><c> which</c><00:02:46.720><c> is</c><00:02:46.800><c> why</c><00:02:46.959><c> you</c>

00:02:47.110 --> 00:02:47.120 align:start position:0%
the foreseeable future, which is why you
 

00:02:47.120 --> 00:02:49.030 align:start position:0%
the foreseeable future, which is why you
need<00:02:47.200><c> to</c><00:02:47.360><c> check</c><00:02:47.519><c> out</c><00:02:47.680><c> Tupil,</c><00:02:48.319><c> the</c><00:02:48.560><c> sponsor</c><00:02:48.879><c> of</c>

00:02:49.030 --> 00:02:49.040 align:start position:0%
need to check out Tupil, the sponsor of
 

00:02:49.040 --> 00:02:50.949 align:start position:0%
need to check out Tupil, the sponsor of
today's<00:02:49.360><c> video.</c><00:02:50.000><c> It's</c><00:02:50.160><c> a</c><00:02:50.319><c> remote</c><00:02:50.640><c> pair</c>

00:02:50.949 --> 00:02:50.959 align:start position:0%
today's video. It's a remote pair
 

00:02:50.959 --> 00:02:53.030 align:start position:0%
today's video. It's a remote pair
programming<00:02:51.440><c> app</c><00:02:51.680><c> for</c><00:02:51.920><c> Mac</c><00:02:52.160><c> OS</c><00:02:52.480><c> and</c><00:02:52.720><c> Windows</c>

00:02:53.030 --> 00:02:53.040 align:start position:0%
programming app for Mac OS and Windows
 

00:02:53.040 --> 00:02:55.270 align:start position:0%
programming app for Mac OS and Windows
that's<00:02:53.280><c> loved</c><00:02:53.599><c> by</c><00:02:53.760><c> teams</c><00:02:54.000><c> at</c><00:02:54.239><c> Shopify,</c><00:02:54.879><c> Clerk,</c>

00:02:55.270 --> 00:02:55.280 align:start position:0%
that's loved by teams at Shopify, Clerk,
 

00:02:55.280 --> 00:02:57.110 align:start position:0%
that's loved by teams at Shopify, Clerk,
and<00:02:55.519><c> many</c><00:02:55.760><c> more.</c><00:02:56.319><c> That's</c><00:02:56.560><c> because</c><00:02:56.800><c> it</c><00:02:56.959><c> gives</c>

00:02:57.110 --> 00:02:57.120 align:start position:0%
and many more. That's because it gives
 

00:02:57.120 --> 00:02:58.869 align:start position:0%
and many more. That's because it gives
you<00:02:57.280><c> high-risisk</c><00:02:57.840><c> screen</c><00:02:58.080><c> sharing</c><00:02:58.480><c> that</c><00:02:58.720><c> lets</c>

00:02:58.869 --> 00:02:58.879 align:start position:0%
you high-risisk screen sharing that lets
 

00:02:58.879 --> 00:03:00.630 align:start position:0%
you high-risisk screen sharing that lets
you<00:02:59.040><c> see</c><00:02:59.120><c> the</c><00:02:59.360><c> tiny</c><00:02:59.680><c> text</c><00:02:59.920><c> in</c><00:03:00.160><c> each</c><00:03:00.319><c> other's</c>

00:03:00.630 --> 00:03:00.640 align:start position:0%
you see the tiny text in each other's
 

00:03:00.640 --> 00:03:02.869 align:start position:0%
you see the tiny text in each other's
IDE,<00:03:01.280><c> plus</c><00:03:01.519><c> shared</c><00:03:01.920><c> remote</c><00:03:02.239><c> control</c><00:03:02.640><c> with</c>

00:03:02.869 --> 00:03:02.879 align:start position:0%
IDE, plus shared remote control with
 

00:03:02.879 --> 00:03:05.110 align:start position:0%
IDE, plus shared remote control with
super<00:03:03.200><c> low</c><00:03:03.440><c> latency,</c><00:03:04.239><c> so</c><00:03:04.400><c> it</c><00:03:04.560><c> feels</c><00:03:04.720><c> like</c><00:03:04.879><c> your</c>

00:03:05.110 --> 00:03:05.120 align:start position:0%
super low latency, so it feels like your
 

00:03:05.120 --> 00:03:06.710 align:start position:0%
super low latency, so it feels like your
team<00:03:05.280><c> is</c><00:03:05.440><c> working</c><00:03:05.680><c> together</c><00:03:06.080><c> on</c><00:03:06.319><c> a</c><00:03:06.480><c> single</c>

00:03:06.710 --> 00:03:06.720 align:start position:0%
team is working together on a single
 

00:03:06.720 --> 00:03:08.710 align:start position:0%
team is working together on a single
machine.<00:03:07.200><c> It's</c><00:03:07.440><c> like</c><00:03:07.599><c> Figma</c><00:03:08.000><c> and</c><00:03:08.159><c> Zoom</c><00:03:08.480><c> had</c><00:03:08.560><c> a</c>

00:03:08.710 --> 00:03:08.720 align:start position:0%
machine. It's like Figma and Zoom had a
 

00:03:08.720 --> 00:03:10.390 align:start position:0%
machine. It's like Figma and Zoom had a
baby<00:03:08.959><c> that</c><00:03:09.200><c> was</c><00:03:09.360><c> built</c><00:03:09.599><c> specifically</c><00:03:10.080><c> for</c>

00:03:10.390 --> 00:03:10.400 align:start position:0%
baby that was built specifically for
 

00:03:10.400 --> 00:03:12.149 align:start position:0%
baby that was built specifically for
developers,<00:03:11.120><c> but</c><00:03:11.280><c> the</c><00:03:11.519><c> entire</c><00:03:11.760><c> app</c><00:03:12.000><c> is</c>

00:03:12.149 --> 00:03:12.159 align:start position:0%
developers, but the entire app is
 

00:03:12.159 --> 00:03:14.470 align:start position:0%
developers, but the entire app is
written<00:03:12.400><c> in</c><00:03:12.560><c> C++,</c><00:03:13.440><c> so</c><00:03:13.599><c> it</c><00:03:13.760><c> won't</c><00:03:13.920><c> hog</c><00:03:14.159><c> all</c><00:03:14.319><c> your</c>

00:03:14.470 --> 00:03:14.480 align:start position:0%
written in C++, so it won't hog all your
 

00:03:14.480 --> 00:03:16.790 align:start position:0%
written in C++, so it won't hog all your
CPU<00:03:14.959><c> cycles</c><00:03:15.360><c> either.</c><00:03:15.840><c> You</c><00:03:16.000><c> can</c><00:03:16.080><c> try</c><00:03:16.239><c> Tupal</c><00:03:16.720><c> for</c>

00:03:16.790 --> 00:03:16.800 align:start position:0%
CPU cycles either. You can try Tupal for
 

00:03:16.800 --> 00:03:18.550 align:start position:0%
CPU cycles either. You can try Tupal for
free<00:03:16.959><c> at</c><00:03:17.120><c> the</c><00:03:17.280><c> link</c><00:03:17.440><c> below,</c><00:03:17.840><c> or</c><00:03:18.080><c> use</c><00:03:18.319><c> code</c>

00:03:18.550 --> 00:03:18.560 align:start position:0%
free at the link below, or use code
 

00:03:18.560 --> 00:03:20.390 align:start position:0%
free at the link below, or use code
fireship<00:03:19.120><c> to</c><00:03:19.200><c> get</c><00:03:19.360><c> a</c><00:03:19.519><c> special</c><00:03:19.760><c> discount</c><00:03:20.159><c> for</c>

00:03:20.390 --> 00:03:20.400 align:start position:0%
fireship to get a special discount for
 

00:03:20.400 --> 00:03:22.149 align:start position:0%
fireship to get a special discount for
your<00:03:20.560><c> entire</c><00:03:20.959><c> team.</c><00:03:21.440><c> This</c><00:03:21.519><c> has</c><00:03:21.680><c> been</c><00:03:21.760><c> the</c><00:03:21.920><c> Code</c>

00:03:22.149 --> 00:03:22.159 align:start position:0%
your entire team. This has been the Code
 

00:03:22.159 --> 00:03:23.990 align:start position:0%
your entire team. This has been the Code
Report.<00:03:22.640><c> Thanks</c><00:03:22.959><c> for</c><00:03:23.120><c> watching</c><00:03:23.440><c> and</c><00:03:23.680><c> I</c><00:03:23.840><c> will</c>

00:03:23.990 --> 00:03:24.000 align:start position:0%
Report. Thanks for watching and I will
 

00:03:24.000 --> 00:03:26.640 align:start position:0%
Report. Thanks for watching and I will
see<00:03:24.159><c> you</c><00:03:24.239><c> in</c><00:03:24.400><c> the</c><00:03:24.560><c> next</c>

